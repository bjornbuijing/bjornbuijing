{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "11.3\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import gin\n",
    "from DataUtils.Getdata import GetDataSets\n",
    "from DataUtils.Getdata import ModuleTest\n",
    "from Models.LineairModelCollection import CNN\n",
    "import Models.LineairModelCollection\n",
    "\n",
    "print(torch.version.cuda)\n",
    "gin.enter_interactive_mode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gin.parse_config_file(\"config.gin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "train_dataloader,test_dataloader = GetDataSets(batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.FashionMNIST"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset\n",
    "type(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "globaLlr = 0.2\n",
    "globalEpochs = 20\n",
    "globalsteps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 11:57:25.924 | INFO     | Training.trainer:RunTrainer:71 - Logging to ..\\trained_models\\20220521-1157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeREs(\n",
      "  (Squeeze): Linear(in_features=28, out_features=1, bias=True)\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (relu): ReLU()\n",
      "  (exite): Linear(in_features=1, out_features=28, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "..\\trained_models\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "only batches of spatial targets supported (3D tensors) but got targets of size: : [64]\n  In call to configurable 'RunTrainer' (<function RunTrainer at 0x000001846934FBE0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\School\\Machine learning\\Clean project\\project\\project\\Test senet.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/School/Machine%20learning/Clean%20project/project/project/Test%20senet.ipynb#ch0000008?line=8'>9</a>\u001b[0m lossCross \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Machine%20learning/Clean%20project/project/project/Test%20senet.ipynb#ch0000008?line=9'>10</a>\u001b[0m lossCross\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/School/Machine%20learning/Clean%20project/project/project/Test%20senet.ipynb#ch0000008?line=11'>12</a>\u001b[0m RunTrainer(model\u001b[39m=\u001b[39;49mmodel, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Machine%20learning/Clean%20project/project/project/Test%20senet.ipynb#ch0000008?line=12'>13</a>\u001b[0m            train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Machine%20learning/Clean%20project/project/project/Test%20senet.ipynb#ch0000008?line=13'>14</a>\u001b[0m            test_dataloader\u001b[39m=\u001b[39;49mtest_dataloader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Machine%20learning/Clean%20project/project/project/Test%20senet.ipynb#ch0000008?line=14'>15</a>\u001b[0m            learning_rate\u001b[39m=\u001b[39;49mglobaLlr,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Machine%20learning/Clean%20project/project/project/Test%20senet.ipynb#ch0000008?line=15'>16</a>\u001b[0m            epochs\u001b[39m=\u001b[39;49mglobalEpochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Machine%20learning/Clean%20project/project/project/Test%20senet.ipynb#ch0000008?line=16'>17</a>\u001b[0m            optimizer\u001b[39m=\u001b[39;49madamOpt,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Machine%20learning/Clean%20project/project/project/Test%20senet.ipynb#ch0000008?line=17'>18</a>\u001b[0m            loss_fn\u001b[39m=\u001b[39;49mlossCross,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Machine%20learning/Clean%20project/project/project/Test%20senet.ipynb#ch0000008?line=18'>19</a>\u001b[0m            eval_steps\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Machine%20learning/Clean%20project/project/project/Test%20senet.ipynb#ch0000008?line=19'>20</a>\u001b[0m            device\u001b[39m=\u001b[39;49mdevice,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Machine%20learning/Clean%20project/project/project/Test%20senet.ipynb#ch0000008?line=20'>21</a>\u001b[0m            )\n",
      "File \u001b[1;32md:\\Development tools\\python\\lib\\site-packages\\gin\\config.py:1032\u001b[0m, in \u001b[0;36m_make_configurable.<locals>.apply_config.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Development%20tools/python/lib/site-packages/gin/config.py?line=1029'>1030</a>\u001b[0m scope_info \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m in scope \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(scope_str) \u001b[39mif\u001b[39;00m scope_str \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   <a href='file:///d%3A/Development%20tools/python/lib/site-packages/gin/config.py?line=1030'>1031</a>\u001b[0m err_str \u001b[39m=\u001b[39m err_str\u001b[39m.\u001b[39mformat(name, fn, scope_info)\n\u001b[1;32m-> <a href='file:///d%3A/Development%20tools/python/lib/site-packages/gin/config.py?line=1031'>1032</a>\u001b[0m utils\u001b[39m.\u001b[39;49maugment_exception_message_and_reraise(e, err_str)\n",
      "File \u001b[1;32md:\\Development tools\\python\\lib\\site-packages\\gin\\utils.py:48\u001b[0m, in \u001b[0;36maugment_exception_message_and_reraise\u001b[1;34m(exception, message)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Development%20tools/python/lib/site-packages/gin/utils.py?line=45'>46</a>\u001b[0m \u001b[39mif\u001b[39;00m six\u001b[39m.\u001b[39mPY3:\n\u001b[0;32m     <a href='file:///d%3A/Development%20tools/python/lib/site-packages/gin/utils.py?line=46'>47</a>\u001b[0m   ExceptionProxy\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(exception)\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[1;32m---> <a href='file:///d%3A/Development%20tools/python/lib/site-packages/gin/utils.py?line=47'>48</a>\u001b[0m   six\u001b[39m.\u001b[39;49mraise_from(proxy\u001b[39m.\u001b[39;49mwith_traceback(exception\u001b[39m.\u001b[39;49m__traceback__), \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m     <a href='file:///d%3A/Development%20tools/python/lib/site-packages/gin/utils.py?line=48'>49</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///d%3A/Development%20tools/python/lib/site-packages/gin/utils.py?line=49'>50</a>\u001b[0m   six\u001b[39m.\u001b[39mreraise(proxy, \u001b[39mNone\u001b[39;00m, sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m])\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32md:\\Development tools\\python\\lib\\site-packages\\gin\\config.py:1009\u001b[0m, in \u001b[0;36m_make_configurable.<locals>.apply_config.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Development%20tools/python/lib/site-packages/gin/config.py?line=1005'>1006</a>\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m   <a href='file:///d%3A/Development%20tools/python/lib/site-packages/gin/config.py?line=1007'>1008</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///d%3A/Development%20tools/python/lib/site-packages/gin/config.py?line=1008'>1009</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39mnew_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n\u001b[0;32m   <a href='file:///d%3A/Development%20tools/python/lib/site-packages/gin/config.py?line=1009'>1010</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Development%20tools/python/lib/site-packages/gin/config.py?line=1010'>1011</a>\u001b[0m   err_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32md:\\School\\Machine learning\\Clean project\\project\\project\\Training\\trainer.py:86\u001b[0m, in \u001b[0;36mRunTrainer\u001b[1;34m(model, train_dataloader, test_dataloader, epochs, optimizer, learning_rate, loss_fn, eval_steps, device, log_dir)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/School/Machine%20learning/Clean%20project/project/project/Training/trainer.py?line=83'>84</a>\u001b[0m target \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='file:///d%3A/School/Machine%20learning/Clean%20project/project/project/Training/trainer.py?line=84'>85</a>\u001b[0m output \u001b[39m=\u001b[39m model(\u001b[39minput\u001b[39m)\n\u001b[1;32m---> <a href='file:///d%3A/School/Machine%20learning/Clean%20project/project/project/Training/trainer.py?line=85'>86</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(output, target)\n\u001b[0;32m     <a href='file:///d%3A/School/Machine%20learning/Clean%20project/project/project/Training/trainer.py?line=86'>87</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='file:///d%3A/School/Machine%20learning/Clean%20project/project/project/Training/trainer.py?line=87'>88</a>\u001b[0m optimizer_\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\Development tools\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Development%20tools/python/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Development%20tools/python/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Development%20tools/python/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///d%3A/Development%20tools/python/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///d%3A/Development%20tools/python/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/Development%20tools/python/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Development%20tools/python/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Development tools\\python\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1163\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Development%20tools/python/lib/site-packages/torch/nn/modules/loss.py?line=1161'>1162</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> <a href='file:///d%3A/Development%20tools/python/lib/site-packages/torch/nn/modules/loss.py?line=1162'>1163</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   <a href='file:///d%3A/Development%20tools/python/lib/site-packages/torch/nn/modules/loss.py?line=1163'>1164</a>\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   <a href='file:///d%3A/Development%20tools/python/lib/site-packages/torch/nn/modules/loss.py?line=1164'>1165</a>\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32md:\\Development tools\\python\\lib\\site-packages\\torch\\nn\\functional.py:2996\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Development%20tools/python/lib/site-packages/torch/nn/functional.py?line=2993'>2994</a>\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///d%3A/Development%20tools/python/lib/site-packages/torch/nn/functional.py?line=2994'>2995</a>\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> <a href='file:///d%3A/Development%20tools/python/lib/site-packages/torch/nn/functional.py?line=2995'>2996</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: only batches of spatial targets supported (3D tensors) but got targets of size: : [64]\n  In call to configurable 'RunTrainer' (<function RunTrainer at 0x000001846934FBE0>)"
     ]
    }
   ],
   "source": [
    "from Models.SeNetModelCollection import SeREs \n",
    "model = SeREs(kernel=3,units=28).to(device)\n",
    "model.cuda()\n",
    "print(model)\n",
    "\n",
    "from Training.trainer import RunTrainer\n",
    "import torch.optim as optim\n",
    "adamOpt = optim.Adam\n",
    "lossCross = torch.nn.CrossEntropyLoss()\n",
    "lossCross.cuda()\n",
    " \n",
    "RunTrainer(model=model, \n",
    "           train_dataloader=train_dataloader,\n",
    "           test_dataloader=test_dataloader,\n",
    "           learning_rate=globaLlr,\n",
    "           epochs=globalEpochs,\n",
    "           optimizer=adamOpt,\n",
    "           loss_fn=lossCross,\n",
    "           eval_steps=3,\n",
    "           device=device,\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(train_dataloader))\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = X[0]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1847b85bc10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sq_units = int(784 / 64) \n",
    "fSqueeze = nn.AdaptiveAvgPool2d(3)\n",
    "fflat = nn.Flatten()\n",
    "fSqueeze = nn.Linear(784, 64)\n",
    "frelu = nn.ReLU()\n",
    "fexite = nn.Linear(64, 784)\n",
    "fsigmoid = nn.Sigmoid()\n",
    "#       \n",
    "\n",
    "x = X[0]\n",
    "skip = x\n",
    "y = fSqueeze(x)\n",
    "y = fflat(x)\n",
    "#y = fSqueeze(x)\n",
    "#y = frelu(x)\n",
    "#y.shape\n",
    "#y = fexite(x)\n",
    "#y = fsigmoid(x)\n",
    "#y = x[..., None, None]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "globaLlr = 0.02\n",
    "globalEpochs = 50\n",
    "globalsteps = 5"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69855e6a671ebbae22bded53bf54a2e55965db9df64dc0686841d36ea41951c3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
