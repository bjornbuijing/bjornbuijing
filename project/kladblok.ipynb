{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "print(\"Device : \" + device)\n",
    "epochs = 15\n",
    "learning_rate = 0.02 #way too high but hopefully quick\n",
    "eval_steps = 3\n",
    "log_dir = '..\\\\trained_models\\\\'\n",
    "log_dir = Path(log_dir)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "log_dir = log_dir / timestamp\n",
    "print(log_dir)\n",
    "clean_dir(log_dir)\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "model = model.to(device)\n",
    "optimizer_ = optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0        \n",
    "    model.train()    \n",
    "    for batch in train_dataloader:\n",
    "        optimizer_.zero_grad()\n",
    "        input, target = batch\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(input)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer_.step()\n",
    "        train_loss += loss.data.item()\n",
    "    train_loss /= len(train_dataloader.dataset)\n",
    "    print(f\"Epoch : {epoch} - train loss ={train_loss}\")\n",
    "    writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0.0\n",
    "    for _ in range(eval_steps):\n",
    "        input, target = next(iter(test_dataloader))\n",
    "        input = input.to(device)        \n",
    "        target = target.to(device)\n",
    "        output = model(input)\n",
    "        loss = loss_fn(output, target)\n",
    "        test_loss += loss.data.item()\n",
    "        test_accuracy += (output.argmax(dim=1) == target).sum()\n",
    "    datasize = eval_steps * test_dataloader.batch_size\n",
    "    test_loss /= datasize\n",
    "    test_accuracy /= datasize\n",
    "    writer.add_scalar(\"Loss/test\", test_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/accuracy\", test_accuracy, epoch)    \n",
    "    print(f\"testloss :{test_loss} -  test accuracy :{test_accuracy}\")\n",
    "write_gin(log_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# Define model\n",
    "class oCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        \n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n",
    "model = CNN().to(device)\n",
    "model.cuda()\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
